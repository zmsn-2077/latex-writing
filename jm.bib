@inproceedings{Dathathri2020Plug,
  title={Plug and Play Language Models: A Simple Approach to Controlled Text Generation},
  author={Sumanth Dathathri and Andrea Madotto and Janice Lan and Jane Hung and Eric Frank and Piero Molino and Jason Yosinski and Rosanne Liu},
  booktitle={International Conference on Learning Representations},
  year={2020}
}

@article{ji2024language,
  title={Language Models Resist Alignment},
  author={Ji, Jiaming and Wang, Kaile and Qiu, Tianyi and Chen, Boyuan and Zhou, Jiayi and Li, Changye and Lou, Hantao and Yang, Yaodong},
  journal={arXiv preprint arXiv:2406.06144},
  year={2024}
}

@book{altman2021constrained,
  title={Constrained Markov decision processes},
  author={Altman, Eitan},
  year={2021},
  publisher={Routledge}
}

@article{ji2024omnisafe,
  title={Omnisafe: An infrastructure for accelerating safe reinforcement learning research},
  author={Ji, Jiaming and Zhou, Jiayi and Zhang, Borong and Dai, Juntao and Pan, Xuehai and Sun, Ruiyang and Huang, Weidong and Geng, Yiran and Liu, Mickel and Yang, Yaodong},
  journal={Journal of Machine Learning Research},
  volume={25},
  number={285},
  pages={1--6},
  year={2024}
}

@article{sun2023aligning,
  title={Aligning large multimodal models with factually augmented rlhf},
  author={Sun, Zhiqing and Shen, Sheng and Cao, Shengcao and Liu, Haotian and Li, Chunyuan and Shen, Yikang and Gan, Chuang and Gui, Liang-Yan and Wang, Yu-Xiong and Yang, Yiming and others},
  journal={arXiv preprint arXiv:2309.14525},
  year={2023}
}

@inproceedings{yu2024rlhf,
  title={Rlhf-v: Towards trustworthy mllms via behavior alignment from fine-grained correctional human feedback},
  author={Yu, Tianyu and Yao, Yuan and Zhang, Haoye and He, Taiwen and Han, Yifeng and Cui, Ganqu and Hu, Jinyi and Liu, Zhiyuan and Zheng, Hai-Tao and Sun, Maosong and others},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={13807--13816},
  year={2024}
}

@article{zhou2024sequence,
  title={Sequence to Sequence Reward Modeling: Improving RLHF by Language Feedback},
  author={Zhou, Jiayi and Ji, Jiaming and Dai, Juntao and Yang, Yaodong},
  journal={arXiv preprint arXiv:2409.00162},
  year={2024}
}

@article{ji2024align,
  title={Align Anything: Training All-Modality Models to Follow Instructions with Language Feedback},
  author={Ji, Jiaming and Zhou, Jiayi and Lou, Hantao and Chen, Boyuan and Hong, Donghai and Wang, Xuyao and Chen, Wenqi and Wang, Kaile and Pan, Rui and Li, Jiahao and others},
  journal={arXiv preprint arXiv:2412.15838},
  year={2024}
}

@article{ji2024pku,
  title={PKU-SafeRLHF: Towards Multi-Level Safety Alignment for LLMs with Human Preference},
  author={Ji, Jiaming and Hong, Donghai and Zhang, Borong and Chen, Boyuan and Dai, Josef and Zheng, Boren and Qiu, Tianyi and Li, Boxun and Yang, Yaodong},
  journal={arXiv preprint arXiv:2406.15513},
  year={2024}
}

@inproceedings{yang2021fudge,
  title={FUDGE: Controlled Text Generation With Future Discriminators},
  author={Yang, Kevin and Klein, Dan},
  booktitle={Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages={3511--3535},
  year={2021}
}

@inproceedings{lu2023inference,
  title={Inference-time policy adapters (ipa): Tailoring extreme-scale lms without fine-tuning},
  author={Lu, Ximing and Brahman, Faeze and West, Peter and Jung, Jaehun and Chandu, Khyathi and Ravichander, Abhilasha and Ammanabrolu, Prithviraj and Jiang, Liwei and Ramnath, Sahana and Dziri, Nouha and others},
  booktitle={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={6863--6883},
  year={2023}
}

@article{min2022rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}

@article{dong2022survey,
  title={A survey on in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}
@article{dubois2024length,
  title={Length-controlled alpacaeval: A simple way to debias automatic evaluators},
  author={Dubois, Yann and Galambosi, Bal{\'a}zs and Liang, Percy and Hashimoto, Tatsunori B},
  journal={arXiv preprint arXiv:2404.04475},
  year={2024}
}

@MISC{noauthor_undated-nz,
  title        = "China: hourly minimum wage by region 2024",
  booktitle    = "Statista",
  abstract     = " In 2024, the minimum hourly wage in Beijing was the highest in China at 26.4 yuan per hour.",
  howpublished = "\url{https://www.statista.com/statistics/233886/minimum-wage-per-hour-in-china-by-city-and-province/}",
  note         = "Accessed: 2024-5-21",
  language     = "en"
}
@article{team2024gemma,
  title={Gemma: Open models based on gemini research and technology},
  author={Team, Gemma and Mesnard, Thomas and Hardin, Cassidy and Dadashi, Robert and Bhupatiraju, Surya and Pathak, Shreya and Sifre, Laurent and Rivi{\`e}re, Morgane and Kale, Mihir Sanjay and Love, Juliette and others},
  journal={arXiv preprint arXiv:2403.08295},
  year={2024}
}
@inproceedings{yang2024rlcd,
title={{RLCD}: Reinforcement Learning from Contrastive Distillation for {LM} Alignment},
author={Kevin Yang and Dan Klein and Asli Celikyilmaz and Nanyun Peng and Yuandong Tian},
booktitle={The Twelfth International Conference on Learning Representations},
year={2024},
url={https://openreview.net/forum?id=v3XXtxWKi6}
}


@article{cheng2023black,
  title={Black-box prompt optimization: Aligning large language models without model training},
  author={Cheng, Jiale and Liu, Xiao and Zheng, Kehan and Ke, Pei and Wang, Hongning and Dong, Yuxiao and Tang, Jie and Huang, Minlie},
  journal={arXiv preprint arXiv:2311.04155},
  year={2023}
}

@article{vernikos2023small,
  title={Small Language Models Improve Giants by Rewriting Their Outputs},
  author={Vernikos, Giorgos and Bra{\v{z}}inskas, Arthur and Adamek, Jakub and Mallinson, Jonathan and Severyn, Aliaksei and Malmi, Eric},
  journal={arXiv preprint arXiv:2305.13514},
  year={2023}
}

@article{jiang2023llm,
  title={Llm-blender: Ensembling large language models with pairwise ranking and generative fusion},
  author={Jiang, Dongfu and Ren, Xiang and Lin, Bill Yuchen},
  journal={arXiv preprint arXiv:2306.02561},
  year={2023}
}

@article{yao2023deepspeed,
  title={Deepspeed-chat: Easy, fast and affordable rlhf training of chatgpt-like models at all scales},
  author={Yao, Zhewei and Aminabadi, Reza Yazdani and Ruwase, Olatunji and Rajbhandari, Samyam and Wu, Xiaoxia and Awan, Ammar Ahmad and Rasley, Jeff and Zhang, Minjia and Li, Conglong and Holmes, Connor and others},
  journal={arXiv preprint arXiv:2308.01320},
  year={2023}
}

@article{bai2022training,
  title={Training a helpful and harmless assistant with reinforcement learning from human feedback},
  author={Bai, Yuntao and Jones, Andy and Ndousse, Kamal and Askell, Amanda and Chen, Anna and DasSarma, Nova and Drain, Dawn and Fort, Stanislav and Ganguli, Deep and Henighan, Tom and others},
  journal={arXiv preprint arXiv:2204.05862},
  year={2022}
}

@inproceedings{rafailov2023direct,
  title={Direct Preference Optimization: Your Language Model is Secretly a Reward Model},
  author={Rafael Rafailov and Archit Sharma and Eric Mitchell and Christopher D Manning and Stefano Ermon and Chelsea Finn},
  booktitle={Thirty-seventh Conference on Neural Information Processing Systems},
  year={2023}
}

@misc{taori2023stanford,
  title={Stanford alpaca: An instruction-following llama model},
  author={Taori, Rohan and Gulrajani, Ishaan and Zhang, Tianyi and Dubois, Yann and Li, Xuechen and Guestrin, Carlos and Liang, Percy and Hashimoto, Tatsunori B},
  year={2023}
}

@misc{sharegpt,
  title={{ShareGPT}},
  author={ShareGPT},
  year=2023,
  howpublished={\url{https://sharegpt.com}}
}
@article{hendrycks2021measuring,
  title={Measuring mathematical problem solving with the math dataset},
  author={Hendrycks, Dan and Burns, Collin and Kadavath, Saurav and Arora, Akul and Basart, Steven and Tang, Eric and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2103.03874},
  year={2021}
}

@article{zheng2023judging,
  title={Judging llm-as-a-judge with mt-bench and chatbot arena},
  author={Zheng, Lianmin and Chiang, Wei-Lin and Sheng, Ying and Zhuang, Siyuan and Wu, Zhanghao and Zhuang, Yonghao and Lin, Zi and Li, Zhuohan and Li, Dacheng and Xing, Eric and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={46595--46623},
  year={2023}
}


@misc{cui2023ultrafeedback,
      title={UltraFeedback: Boosting Language Models with High-quality Feedback}, 
      author={Ganqu Cui and Lifan Yuan and Ning Ding and Guanming Yao and Wei Zhu and Yuan Ni and Guotong Xie and others},
      year={2023},
      eprint={2310.01377},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{hendrycks2020measuring,
  title={Measuring massive multitask language understanding},
  author={Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal={arXiv preprint arXiv:2009.03300},
  year={2020}
}


@article{chen2021evaluating,
  title={Evaluating large language models trained on code},
  author={Chen, Mark and Tworek, Jerry and Jun, Heewoo and Yuan, Qiming and Pinto, Henrique Ponde De Oliveira and Kaplan, Jared and Edwards, Harri and Burda, Yuri and Joseph, Nicholas and Brockman, Greg and others},
  journal={arXiv preprint arXiv:2107.03374},
  year={2021}
}


@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  year={2023}
}

@article{touvron2023llama,
  title={Llama 2: Open foundation and fine-tuned chat models},
  author={Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and others},
  journal={arXiv preprint arXiv:2307.09288},
  year={2023}
}

@article{askell2021general,
  title={A general language assistant as a laboratory for alignment},
  author={Askell, Amanda and Bai, Yuntao and Chen, Anna and Drain, Dawn and Ganguli, Deep and Henighan, Tom and Jones, Andy and Joseph, Nicholas and Mann, Ben and DasSarma, Nova and others},
  journal={arXiv preprint arXiv:2112.00861},
  year={2021}
}

@article{anwar2024foundational,
  title={Foundational challenges in assuring alignment and safety of large language models},
  author={Anwar, Usman and Saparov, Abulhair and Rando, Javier and Paleka, Daniel and Turpin, Miles and Hase, Peter and Lubana, Ekdeep Singh and Jenner, Erik and Casper, Stephen and Sourbut, Oliver and others},
  journal={arXiv preprint arXiv:2404.09932},
  year={2024}
}

@inproceedings{rashkin2019towards,
  title={Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset},
  author={Rashkin, Hannah and Smith, Eric Michael and Li, Margaret and Boureau, Y-Lan},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={5370--5381},
  year={2019}
}

@inproceedings{chen2021dialogsum,
  title={DialogSum: A Real-Life Scenario Dialogue Summarization Dataset},
  author={Chen, Yulong and Liu, Yang and Chen, Liang and Zhang, Yue},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={5062--5074},
  year={2021}
}

@article{ji2024beavertails,
  title={Beavertails: Towards improved safety alignment of llm via a human-preference dataset},
  author={Ji, Jiaming and Liu, Mickel and Dai, Josef and Pan, Xuehai and Zhang, Chi and Bian, Ce and Chen, Boyuan and Sun, Ruiyang and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{bhardwaj2023red,
  title={Red-teaming large language models using chain of utterances for safety-alignment},
  author={Bhardwaj, Rishabh and Poria, Soujanya},
  journal={arXiv preprint arXiv:2308.09662},
  year={2023}
}

inproceedings{lin2022truthfulqa,
  title={TruthfulQA: Measuring How Models Mimic Human Falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={3214--3252},
  year={2022}
}

@article{lin2022truthfulqa,
  title={Truthfulqa: Measuring how models mimic human falsehoods},
  author={Lin, Stephanie and Hilton, Jacob and Evans, Owain},
  journal={arXiv preprint arXiv:2109.07958},
  year={2021}
}

@misc{anthropic2024claude3,
  title={{Claude 3}},
  author={Anthropic},
  year=2024,
  howpublished={\url{https://www.anthropic.com/news/claude-3-family}},
}

@misc{anthropic2023claude2,
  title={{Claude 2}},
  author={Anthropic},
  year=2023,
  howpublished={\url{https://www.anthropic.com/news/claude-2}},
}

@article{kaplan2020scaling,
  title={Scaling laws for neural language models},
  author={Kaplan, Jared and McCandlish, Sam and Henighan, Tom and Brown, Tom B and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario},
  journal={arXiv preprint arXiv:2001.08361},
  year={2020}
}

@inproceedings{dai2024safe,
  author = {Josef Dai and Xuehai Pan and Ruiyang Sun and Jiaming Ji and Xinbo Xu and Mickel Liu and Yizhou Wang and Yaodong Yang},
  booktitle = {The Twelfth International Conference on Learning Representations},
  title = {Safe RLHF: Safe Reinforcement Learning from Human Feedback},
  year = {2024}
}

@article{bai2022constitutional,
  title={Constitutional ai: Harmlessness from ai feedback},
  author={Bai, Yuntao and Kadavath, Saurav and Kundu, Sandipan and Askell, Amanda and Kernion, Jackson and Jones, Andy and Chen, Anna and Goldie, Anna and Mirhoseini, Azalia and McKinnon, Cameron and others},
  journal={arXiv preprint arXiv:2212.08073},
  year={2022}
}

@article{saunders2022self,
  title={Self-critiquing models for assisting human evaluators},
  author={Saunders, William and Yeh, Catherine and Wu, Jeff and Bills, Steven and Ouyang, Long and Ward, Jonathan and Leike, Jan},
  journal={arXiv preprint arXiv:2206.05802},
  year={2022}
}

@article{madaan2024self,
  title={Self-refine: Iterative refinement with self-feedback},
  author={Madaan, Aman and Tandon, Niket and Gupta, Prakhar and Hallinan, Skyler and Gao, Luyu and Wiegreffe, Sarah and Alon, Uri and Dziri, Nouha and Prabhumoye, Shrimai and Yang, Yiming and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{burns2023weak,
  title={Weak-to-strong generalization: Eliciting strong capabilities with weak supervision},
  author={Burns, Collin and Izmailov, Pavel and Kirchner, Jan Hendrik and Baker, Bowen and Gao, Leo and Aschenbrenner, Leopold and Chen, Yining and Ecoffet, Adrien and Joglekar, Manas and Leike, Jan and Sutskever, Ilya and Wu, Jeff},
  journal={arXiv preprint arXiv:2312.09390},
  year={2023}
}

@article{tarvainen2017mean,
  title={Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results},
  author={Tarvainen, Antti and Valpola, Harri},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{yuan2024rrhf,
  author = {Yuan, Hongyi and Yuan, Zheng and Tan, Chuanqi and Wang, Wei and Huang, Songfang and Huang, Fei},
  journal = {Advances in Neural Information Processing Systems},
  title = {RRHF: Rank responses to align language models with human feedback},
  volume = {36},
  year = {2024}
}


@article{gulcehre2023reinforced,
  title={Reinforced self-training (rest) for language modeling},
  author={Gulcehre, Caglar and Paine, Tom Le and Srinivasan, Srivatsan and Konyushkova, Ksenia and Weerts, Lotte and Sharma, Abhishek and Siddhant, Aditya and Ahern, Alex and Wang, Miaosen and Gu, Chenjie and others},
  journal={arXiv preprint arXiv:2308.08998},
  year={2023}
}

@article{lee2023rlaif,
  title={Rlaif: Scaling reinforcement learning from human feedback with ai feedback},
  author={Lee, Harrison and Phatale, Samrat and Mansoor, Hassan and Lu, Kellie and Mesnard, Thomas and Bishop, Colton and Carbune, Victor and Rastogi, Abhinav},
  journal={arXiv preprint arXiv:2309.00267},
  year={2023}
}

@article{wei2022emergent,
  title={Emergent Abilities of Large Language Models},
  author={Jason Wei and Yi Tay and Rishi Bommasani and Colin Raffel and Barret Zoph and Sebastian Borgeaud and Dani Yogatama and Maarten Bosma and Denny Zhou and Donald Metzler and Ed H. Chi and Tatsunori Hashimoto and Oriol Vinyals and Percy Liang and Jeff Dean and William Fedus},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2022},
  note={Survey Certification}
}

@article{zhao2023survey,
  title={A survey of large language models},
  author={Zhao, Wayne Xin and Zhou, Kun and Li, Junyi and Tang, Tianyi and Wang, Xiaolei and Hou, Yupeng and Min, Yingqian and Zhang, Beichen and Zhang, Junjie and Dong, Zican and others},
  journal={arXiv preprint arXiv:2303.18223},
  year={2023}
}

@article{openai2023gpt4,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}


@misc{together2023redpajama,
  title={{RedPajama: an Open Dataset for Training Large Language Models}},
  author={Together Computer},
  year=2023,
  howpublished={\url{https://github.com/togethercomputer/RedPajama-Data}},
}

@article{yang2023baichuan,
  title={Baichuan 2: Open large-scale language models},
  author={Yang, Aiyuan and Xiao, Bin and Wang, Bingning and Zhang, Borong and Bian, Ce and Yin, Chao and Lv, Chenxu and Pan, Da and Wang, Dian and Yan, Dong and others},
  journal={arXiv preprint arXiv:2309.10305},
  year={2023}
}

@article{anil2023palm2,
  title={Palm 2 technical report},
  author={Anil, Rohan and Dai, Andrew M and Firat, Orhan and Johnson, Melvin and Lepikhin, Dmitry and Passos, Alexandre and Shakeri, Siamak and Taropa, Emanuel and Bailey, Paige and Chen, Zhifeng and others},
  journal={arXiv preprint arXiv:2305.10403},
  year={2023}
}

@inproceedings{deshpande2023toxicity,
  title={Toxicity in chatgpt: Analyzing persona-assigned language models},
  author={Ameet Deshpande and Vishvak Murahari and Tanmay Rajpurohit and Ashwin Kalyan and Karthik R Narasimhan},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023}
}

@article{ji2023survey,
  title={Survey of hallucination in natural language generation},
  author={Ji, Ziwei and Lee, Nayeon and Frieske, Rita and Yu, Tiezheng and Su, Dan and Xu, Yan and Ishii, Etsuko and Bang, Ye Jin and Madotto, Andrea and Fung, Pascale},
  journal={ACM Computing Surveys},
  volume={55},
  number={12},
  pages={1--38},
  year={2023},
  publisher={ACM New York, NY}
}

@inproceedings{li2023multi,
  title={Multi-step Jailbreaking Privacy Attacks on Chat{GPT}},
  author={Haoran Li and Dadi Guo and Wei Fan and Mingshi Xu and Jie Huang and Fanpu Meng and Yangqiu Song},
  booktitle={The 2023 Conference on Empirical Methods in Natural Language Processing},
  year={2023},
}


@article{nasr2023scalable,
  title={Scalable extraction of training data from (production) language models},
  author={Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{\`e}r, Florian and Lee, Katherine},
  journal={arXiv preprint arXiv:2311.17035},
  year={2023}
}

@inproceedings{mita2020self,
  title={A Self-Refinement Strategy for Noise Reduction in Grammatical Error Correction},
  author={Mita, Masato and Kiyono, Shun and Kaneko, Masahiro and Suzuki, Jun and Inui, Kentaro},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
  pages={267--280},
  year={2020}
}

@inproceedings{reid2022learning,
  title={Learning to Model Editing Processes},
  author={Reid, Machel and Neubig, Graham},
  booktitle={Findings of the Association for Computational Linguistics: EMNLP 2022},
  pages={3822--3832},
  year={2022}
}
@article{yang2023idea2img,
  title={Idea2img: Iterative self-refinement with gpt-4v (ision) for automatic image design and generation},
  author={Yang, Zhengyuan and Wang, Jianfeng and Li, Linjie and Lin, Kevin and Lin, Chung-Ching and Liu, Zicheng and Wang, Lijuan},
  journal={arXiv preprint arXiv:2310.08541},
  year={2023}
}

@inproceedings{chen2024teaching,
    title={Teaching Large Language Models to Self-Debug},
    author={Xinyun Chen and Maxwell Lin and Nathanael Sch{\"a}rli and Denny Zhou},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024},
}
@article{christiano2018supervising,
  title={Supervising strong learners by amplifying weak experts},
  author={Christiano, Paul and Shlegeris, Buck and Amodei, Dario},
  journal={arXiv preprint arXiv:1810.08575},
  year={2018}
}

@article{amodei2016concrete,
  title={Concrete problems in AI safety},
  author={Amodei, Dario and Olah, Chris and Steinhardt, Jacob and Christiano, Paul and Schulman, John and Man{\'e}, Dan},
  journal={arXiv preprint arXiv:1606.06565},
  year={2016}
}

@inproceedings{ngo2024the,
    title={The Alignment Problem from a Deep Learning Perspective: A Position Paper},
    author={Richard Ngo and Lawrence Chan and S{\"o}ren Mindermann},
    booktitle={The Twelfth International Conference on Learning Representations},
    year={2024}
}

@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}

@inproceedings{kwon2023efficient,
  title={Efficient memory management for large language model serving with pagedattention},
  author={Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph and Zhang, Hao and Stoica, Ion},
  booktitle={Proceedings of the 29th Symposium on Operating Systems Principles},
  pages={611--626},
  year={2023}
}



@article{ji2023ai,
  title={Ai alignment: A comprehensive survey},
  author={Ji, Jiaming and Qiu, Tianyi and Chen, Boyuan and Zhang, Borong and Lou, Hantao and Wang, Kaile and Duan, Yawen and He, Zhonghao and Zhou, Jiayi and Zhang, Zhaowei and others},
  journal={arXiv preprint arXiv:2310.19852},
  year={2023}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeffrey and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@inproceedings{zheng2024large,
  title={Large Language Models Are Not Robust Multiple Choice Selectors},
  author={Chujie Zheng and Hao Zhou and Fandong Meng and Jie Zhou and Minlie Huang},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2024},
}


@article{na2024switching,
  title={Switching Temporary Teachers for Semi-Supervised Semantic Segmentation},
  author={Na, Jaemin and Ha, Jung-Woo and Chang, Hyung Jin and Han, Dongyoon and Hwang, Wonjun},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}

@misc{superalignment,
	title        = {Introducing Superalignment},
	author       = {OpenAI},
	year         = 2023,
	note         = {Accessed on July 5, 2023},
	howpublished = {\url{https://openai.com/blog/introducing-superalignment}}
}
@article{casper2023open,
  title={Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback},
  author={Stephen Casper and Xander Davies and Claudia Shi and Thomas Krendl Gilbert and J{\'e}r{\'e}my Scheurer and Javier Rando and Rachel Freedman and Tomasz Korbak and David Lindner and others},
  journal={Transactions on Machine Learning Research},
  issn={2835-8856},
  year={2023},
  note={Survey Certification}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}
@article{christiano2017deep,
	title        = {Deep reinforcement learning from human preferences},
	author       = {Christiano, Paul F and Leike, Jan and Brown, Tom and Martic, Miljan and Legg, Shane and Amodei, Dario},
	year         = 2017,
	journal      = {Advances in Neural Information Processing Systems (NeurIPS)},
	volume       = 30
}
@article{zou2023representation,
  title={Representation engineering: A top-down approach to ai transparency},
  author={Zou, Andy and Phan, Long and Chen, Sarah and Campbell, James and Guo, Phillip and Ren, Richard and Pan, Alexander and Yin, Xuwang and Mazeika, Mantas and Dombrowski, Ann-Kathrin and others},
  journal={arXiv preprint arXiv:2310.01405},
  year={2023}
}

@article{turner2023activation,
  title={Activation addition: Steering language models without optimization},
  author={Turner, Alex and Thiergart, Lisa and Udell, David and Leech, Gavin and Mini, Ulisse and MacDiarmid, Monte},
  journal={arXiv preprint arXiv:2308.10248},
  year={2023}
}

@article{li2024inference,
  title={Inference-time intervention: Eliciting truthful answers from a language model},
  author={Li, Kenneth and Patel, Oam and Vi{\'e}gas, Fernanda and Pfister, Hanspeter and Wattenberg, Martin},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}

@article{subramani2022extracting,
  title={Extracting latent steering vectors from pretrained language models},
  author={Subramani, Nishant and Suresh, Nivedita and Peters, Matthew E},
  journal={arXiv preprint arXiv:2205.05124},
  year={2022}
}

@inproceedings{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I and others},
  booktitle={Soviet physics doklady},
  volume={10},
  pages={707--710},
  year={1966},
  organization={Soviet Union}
}

@inproceedings{yin2022interpreting,
  title={Interpreting Language Models with Contrastive Explanations},
  author={Yin, Kayo and Neubig, Graham},
  booktitle={Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing},
  pages={184--198},
  year={2022}
}

% Use this file for citations not found in the ACL Anthology (contained in "anthology.bib").

@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}

@misc{openai2024o1,
  author = {OpenAI},
  title = {Introducing OpenAI o1-preview},
  howpublished = {\url{https://openai.com/index/introducing-openai-o1-preview}},
  year = {2024}
}

@inproceedings{harika2022review,
  title={A review on artificial intelligence with deep human reasoning},
  author={Harika, Janmanchi and Baleeshwar, Palavadi and Navya, Kummari and Shanmugasundaram, Hariharan},
  booktitle={2022 International Conference on Applied Artificial Intelligence and Computing (ICAAIC)},
  pages={81--84},
  year={2022},
  organization={IEEE}
}

@incollection{wang2020cognitive,
  title={Cognitive intelligence: Deep learning, thinking, and reasoning by brain-inspired systems},
  author={Wang, Yingxu and Widrow, Bernard Carlos and Zadeh, Lotfi A and Howard, Newton and Wood, Sally and Bhavsar, Virendrakumar C and Budin, Gerhard and Chan, Christine W and Fiorini, Rodolfo A and Gavrilova, Marina L and others},
  booktitle={Deep Learning and Neural Networks: Concepts, Methodologies, Tools, and Applications},
  pages={1500--1523},
  year={2020},
  publisher={IGI Global}
}

@article{team2023gemini,
  title={Gemini: a family of highly capable multimodal models},
  author={Team, Gemini and Anil, Rohan and Borgeaud, Sebastian and Alayrac, Jean-Baptiste and Yu, Jiahui and Soricut, Radu and Schalkwyk, Johan and Dai, Andrew M and Hauth, Anja and Millican, Katie and others},
  journal={arXiv preprint arXiv:2312.11805},
  year={2023}
}

@article{dubey2024llama,
  title={The llama 3 herd of models},
  author={Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{guo2025deepseek,
  title={Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning},
  author={Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and others},
  journal={arXiv preprint arXiv:2501.12948},
  year={2025}
}

@article{ji2025safe,
  title={Safe RLHF-V: Safe Reinforcement Learning from Human Feedback in Multimodal Large Language Models},
  author={Ji, Jiaming and Chen, Xinyu and Pan, Rui and Zhu, Han and Zhang, Conghui and Li, Jiahao and Hong, Donghai and Chen, Boyuan and Zhou, Jiayi and Wang, Kaile and others},
  journal={arXiv preprint arXiv:2503.17682},
  year={2025}
}

@article{ziegler2019fine,
  title={Fine-tuning language models from human preferences},
  author={Ziegler, Daniel M and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  journal={arXiv preprint arXiv:1909.08593},
  year={2019}
}

@article{qwen2,
  title={Qwen2 Technical Report}, 
  author={An Yang and Baosong Yang and Binyuan Hui and Bo Zheng and Bowen Yu and Chang Zhou and Chengpeng Li and Chengyuan Li and Dayiheng Liu and Fei Huang and Guanting Dong and Haoran Wei and Huan Lin and Jialong Tang and Jialin Wang and Jian Yang and Jianhong Tu and Jianwei Zhang and Jianxin Ma and Jin Xu and Jingren Zhou and Jinze Bai and Jinzheng He and Junyang Lin and Kai Dang and Keming Lu and Keqin Chen and Kexin Yang and Mei Li and Mingfeng Xue and Na Ni and Pei Zhang and Peng Wang and Ru Peng and Rui Men and Ruize Gao and Runji Lin and Shijie Wang and Shuai Bai and Sinan Tan and Tianhang Zhu and Tianhao Li and Tianyu Liu and Wenbin Ge and Xiaodong Deng and Xiaohuan Zhou and Xingzhang Ren and Xinyu Zhang and Xipin Wei and Xuancheng Ren and Yang Fan and Yang Yao and Yichang Zhang and Yu Wan and Yunfei Chu and Yuqiong Liu and Zeyu Cui and Zhenru Zhang and Zhihao Fan},
  journal={arXiv preprint arXiv:2407.10671},
  year={2024}
}

@article{Qwen2VL,
  title={Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution},
  author={Wang, Peng and Bai, Shuai and Tan, Sinan and Wang, Shijie and Fan, Zhihao and Bai, Jinze and Chen, Keqin and Liu, Xuejing and Wang, Jialin and Ge, Wenbin and Fan, Yang and Dang, Kai and Du, Mengfei and Ren, Xuancheng and Men, Rui and Liu, Dayiheng and Zhou, Chang and Zhou, Jingren and Lin, Junyang},
  journal={arXiv preprint arXiv:2409.12191},
  year={2024}
}
@article{gemma_2025,
  title={Gemma 3},
  url={https://goo.gle/Gemma3Report},
  publisher={Kaggle},
  author={Gemma Team},
  year={2025}
}
@article{greenblatt2024alignment,
  title={Alignment faking in large language models},
  author={Greenblatt, Ryan and Denison, Carson and Wright, Benjamin and Roger, Fabien and MacDiarmid, Monte and Marks, Sam and Treutlein, Johannes and Belonax, Tim and Chen, Jack and Duvenaud, David and others},
  journal={arXiv preprint arXiv:2412.14093},
  year={2024}
}
@misc{openai2024gpt4o,
  title={{GPT4o}},
  author={OpenAI},
  year=2024,
  howpublished={\url{https://openai.com/index/hello-gpt-4o/}},
}
@article{park2024ai,
  title={AI deception: A survey of examples, risks, and potential solutions},
  author={Park, Peter S and Goldstein, Simon and Oâ€™Gara, Aidan and Chen, Michael and Hendrycks, Dan},
  journal={Patterns},
  volume={5},
  number={5},
  year={2024},
  publisher={Elsevier}
}

@article{zhang2024spa,
  title={Spa-vl: A comprehensive safety preference alignment dataset for vision language model},
  author={Zhang, Yongting and Chen, Lu and Zheng, Guodong and Gao, Yifeng and Zheng, Rui and Fu, Jinlan and Yin, Zhenfei and Jin, Senjie and Qiao, Yu and Huang, Xuanjing and others},
  journal={arXiv preprint arXiv:2406.12030},
  year={2024}
}
@article{qi2024safety,
  title={Safety alignment should be made more than just a few tokens deep},
  author={Qi, Xiangyu and Panda, Ashwinee and Lyu, Kaifeng and Ma, Xiao and Roy, Subhrajit and Beirami, Ahmad and Mittal, Prateek and Henderson, Peter},
  journal={arXiv preprint arXiv:2406.05946},
  year={2024}
}
@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}
@inproceedings{zeng2024johnny,
  title={How johnny can persuade llms to jailbreak them: Rethinking persuasion to challenge ai safety by humanizing llms},
  author={Zeng, Yi and Lin, Hongpeng and Zhang, Jingwen and Yang, Diyi and Jia, Ruoxi and Shi, Weiyan},
  booktitle={Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={14322--14350},
  year={2024}
}

@article{chao2024jailbreakbench,
  title={Jailbreakbench: An open robustness benchmark for jailbreaking large language models},
  author={Chao, Patrick and Debenedetti, Edoardo and Robey, Alexander and Andriushchenko, Maksym and Croce, Francesco and Sehwag, Vikash and Dobriban, Edgar and Flammarion, Nicolas and Pappas, George J and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2404.01318},
  year={2024}
}
@article{souly2024strongreject,
  title={A strongreject for empty jailbreaks},
  author={Souly, Alexandra and Lu, Qingyuan and Bowen, Dillon and Trinh, Tu and Hsieh, Elvis and Pandey, Sana and Abbeel, Pieter and Svegliato, Justin and Emmons, Scott and Watkins, Olivia and others},
  journal={arXiv preprint arXiv:2402.10260},
  year={2024}
}

@article{meinke2024frontier,
  title={Frontier models are capable of in-context scheming},
  author={Meinke, Alexander and Schoen, Bronson and Scheurer, J{\'e}r{\'e}my and Balesni, Mikita and Shah, Rusheb and Hobbhahn, Marius},
  journal={arXiv preprint arXiv:2412.04984},
  year={2024}
}

@article{baker2025monitoring,
  title={Monitoring Reasoning Models for Misbehavior and the Risks of Promoting Obfuscation},
  author={Baker, Bowen and Huizinga, Joost and Gao, Leo and Dou, Zehao and Guan, Melody Y and Madry, Aleksander and Zaremba, Wojciech and Pachocki, Jakub and Farhi, David},
  journal={arXiv preprint arXiv:2503.11926},
  year={2025}
}

@article{skalse2022defining,
  title={Defining and characterizing reward gaming},
  author={Skalse, Joar and Howe, Nikolaus and Krasheninnikov, Dmitrii and Krueger, David},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={9460--9471},
  year={2022}
}


@inproceedings{perez2023discovering,
  title={Discovering language model behaviors with model-written evaluations},
  author={Perez, Ethan and Ringer, Sam and Lukosiute, Kamile and Nguyen, Karina and Chen, Edwin and Heiner, Scott and Pettit, Craig and Olsson, Catherine and Kundu, Sandipan and Kadavath, Saurav and others},
  booktitle={Findings of the Association for Computational Linguistics: ACL 2023},
  pages={13387--13434},
  year={2023}
}

@article{pan2024frontier,
  title={Frontier AI systems have surpassed the self-replicating red line},
  author={Pan, Xudong and Dai, Jiarun and Fan, Yihe and Yang, Min},
  journal={arXiv preprint arXiv:2412.12140},
  year={2024}
}

@article{van2024ai,
  title={Ai sandbagging: Language models can strategically underperform on evaluations},
  author={van der Weij, Teun and Hofst{\"a}tter, Felix and Jaffe, Ollie and Brown, Samuel F and Ward, Francis Rhys},
  journal={arXiv preprint arXiv:2406.07358},
  year={2024}
}


@misc{openaio1,
  title={Learning to reason with LLMs},
  author={OpenAI},
  year=2024,
  note={Accessed on September 12, 2024},
  howpublished = {\url{https://openai.com/index/learning-to-reason-with-llms}}
}

@article{zhang2024o1,
  title={o1-coder: an o1 replication for coding},
  author={Zhang, Yuxiang and Wu, Shangxi and Yang, Yuqi and Shu, Jiangming and Xiao, Jinlin and Kong, Chao and Sang, Jitao},
  journal={arXiv preprint arXiv:2412.00154},
  year={2024}
}

@article{li2025search,
  title={Search-o1: Agentic search-enhanced large reasoning models},
  author={Li, Xiaoxi and Dong, Guanting and Jin, Jiajie and Zhang, Yuyao and Zhou, Yujia and Zhu, Yutao and Zhang, Peitian and Dou, Zhicheng},
  journal={arXiv preprint arXiv:2501.05366},
  year={2025}
}

@article{bengio2024managing,
  title={Managing extreme AI risks amid rapid progress},
  author={Bengio, Yoshua and Hinton, Geoffrey and Yao, Andrew and Song, Dawn and Abbeel, Pieter and Darrell, Trevor and Harari, Yuval Noah and Zhang, Ya-Qin and Xue, Lan and Shalev-Shwartz, Shai and others},
  journal={Science},
  volume={384},
  number={6698},
  pages={842--845},
  year={2024},
  publisher={American Association for the Advancement of Science}
}

@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}

@article{apley2020visualizing,
  title={Visualizing the effects of predictor variables in black box supervised learning models},
  author={Apley, Daniel W and Zhu, Jingyu},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={82},
  number={4},
  pages={1059--1086},
  year={2020},
  publisher={Oxford University Press}
}

@article{guidotti2018survey,
  title={A survey of methods for explaining black box models},
  author={Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
  journal={ACM computing surveys (CSUR)},
  volume={51},
  number={5},
  pages={1--42},
  year={2018},
  publisher={ACM New York, NY, USA}
}
@inproceedings{carlini2017towards,
  title={Towards evaluating the robustness of neural networks},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2017 ieee symposium on security and privacy (sp)},
  pages={39--57},
  year={2017},
  organization={Ieee}
}
@article{inan2023llama,
  title={Llama guard: Llm-based input-output safeguard for human-ai conversations},
  author={Inan, Hakan and Upasani, Kartikeya and Chi, Jianfeng and Rungta, Rashi and Iyer, Krithika and Mao, Yuning and Tontchev, Michael and Hu, Qing and Fuller, Brian and Testuggine, Davide and others},
  journal={arXiv preprint arXiv:2312.06674},
  year={2023}
}

@article{baker2025monitoring,
  title={Monitoring reasoning models for misbehavior and the risks of promoting obfuscation},
  author={Baker, Bowen and Huizinga, Joost and Gao, Leo and Dou, Zehao and Guan, Melody Y and Madry, Aleksander and Zaremba, Wojciech and Pachocki, Jakub and Farhi, David},
  journal={arXiv preprint arXiv:2503.11926},
  year={2025}
}
